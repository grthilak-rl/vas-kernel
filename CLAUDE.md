You are implementing VAS Kernel & AI Platform Phases incrementally.

VAS is a frozen reference implementation.
All existing behavior is correct and non-negotiable.

The current ACTIVE phase MUST be explicitly stated in the prompt.
Only the ACTIVE phase may be implemented.

If unsure, STOP and ASK.

===============================
ABSOLUTE RULES (DO NOT VIOLATE)
===============================
• Do NOT use emojis in code
• Do NOT modify MediaSoup behavior or lifecycle
• Do NOT modify FFmpeg invocation, flags, or control flow
• Do NOT modify RTSP ingest or reconnect logic
• Do NOT refactor existing architecture
• Do NOT rename services, files, or modules
• Do NOT change existing backend APIs unless explicitly instructed
• Do NOT introduce new frameworks, transports, or protocols
• Do NOT introduce HTTP / WebSocket / gRPC frame streaming
• Do NOT block, delay, or back-pressure video decode

If unsure, STOP and ASK.

===============================
PHASE STATUS (AUTHORITATIVE)
===============================

Phase 1 – Frame Ring Buffer: COMPLETED
Phase 2 – Frame Export Interface: COMPLETED

Phase 3.1 – Stream Agent Internal State Model: COMPLETED
Phase 3.2 – Subscription Model & Frame Binding: COMPLETED
Phase 3.3 – FPS Scheduling & Frame Selection: COMPLETED
Phase 3.4 – Failure & Restart Semantics: COMPLETED

Phase 4.1 – AI Model IPC & Inference Contract: COMPLETED
Phase 4.2 – AI Model Runtime & Onboarding: COMPLETED

Phase 5.1 – AI Event Schema + Persistence: COMPLETED
Phase 5.2 – Snapshot / Clip Triggers: COMPLETED
Phase 5.3 – Read-only Backend APIs: COMPLETED

Phase 6.1 – Frontend Overlay Data Wiring: COMPLETED
Phase 6.2 – Frontend Overlay Rendering: COMPLETED
Phase 6.3 – Frontend UX Controls & Filters: COMPLETED

Phase 7 – Observability & Operational Controls: COMPLETED

Phase 8.1 – Backend Model Assignment APIs: COMPLETED
Phase 8.2 – Ruth AI Core Subscription Reconciliation: COMPLETED
Phase 8.3 – Frontend Model Selection UI: ACTIVE

Only phases marked ACTIVE may be implemented.
All other phases are FROZEN and must not be modified.

===============================
FEATURE FLAGS (MANDATORY)
===============================

All Phase 1 and Phase 2 logic MUST be guarded by:

AI_FRAME_EXPORT_ENABLED=false

When false:
• No frame buffers allocated
• No shared memory created
• No frame copies
• Zero overhead

===============================
ARCHITECTURE (NON-NEGOTIABLE)
===============================

Frame tap point is ONLY at the FFmpeg decode boundary:

RTSP → FFmpeg decode → RAW FRAME
                         ├── Recording (existing)
                         ├── MediaSoup Producer (existing)
                         └── Kernel Frame Path (Phase 1 / Phase 2)

Do NOT tap frames:
• after MediaSoup
• after recording
• inside AI code
• inside WebRTC code

===============================
PHASE 8.3 – FRONTEND MODEL SELECTION UI (ACTIVE)
===============================

Phase 8.3 introduces the **final control-plane UI** for AI execution.

Phase 8.3 IS:
• Frontend UI to view available AI models
• Frontend UI to view per-camera model assignments
• User-driven enable / disable of models per camera
• Configuration of assignment intent (fps, priority, parameters)
• Calls ONLY Phase 8.1 backend assignment APIs
• Read-only visibility into current assignment state
• Control-plane UI only (intent management)

Phase 8.3 IS NOT:
• AI inference logic
• Model container lifecycle control
• Direct interaction with Ruth AI Core
• Subscription reconciliation logic (Phase 8.2)
• Overlay rendering or visualization (Phase 6)
• Observability or metrics (Phase 7)
• Snapshot, clip, or violation logic
• Analytics or reporting

Frontend MUST:
• Treat backend as the source of truth
• Never assume execution state
• Never talk to model containers
• Never start or stop inference directly
• Never affect video playback or ingestion
• Fail silently on errors
• Be fully optional and non-blocking

===============================
FAILURE & ISOLATION (GLOBAL)
===============================

Inherited from Phase 3.4 and applies globally:
• VAS failure → outside AI scope
• AI Core failure → VAS unaffected
• Model container failure → isolated
• GPU failure → container-local
• Bad frame → request fails, no retry

The system MUST NOT:
• Retry inference automatically
• Buffer frames
• Coordinate restarts
• Perform recovery logic
• Emit alerts automatically

Failures are fail-closed and lossy by design.

===============================
WHAT NOT TO IMPLEMENT (GLOBAL)
===============================
• Modifying existing VAS video paths
• AI inference inside VAS
• Network frame streaming
• Backend API changes
• Reconciliation or execution logic
• Model onboarding or loading logic
• Model container lifecycle control
• Observability or metrics changes
• Alerting or notification systems
• Business analytics or violation reports
• Multi-host GPU orchestration

===============================
OUTPUT EXPECTATION
===============================
• Minimal, surgical diffs
• Fully reversible changes
• Well-commented where correctness is critical
• No behavior changes outside the ACTIVE phase

If any change risks violating these constraints,
STOP and ASK before proceeding.